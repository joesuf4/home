# Oracle Cloud Infrastructure        -*- sh -*-

# Notes:
# GNU-specific utility tooling throughout (primarily built to /usr/local)
# _oci_$foo take no arguments: you must set $region and $ad in the env

_oci_pre_sync () {
  echo Preparing $region with $ad Availability Domains.

  echo Step 1. Intitialize ssh, create password, and bootstrap RBAC.

  echo Step 2. Disable Firewall and attach ISCSI devices manually.
  oci_region_exec $region sudo svcadm disable firewall
  for id in {1..$ad}
  do
    echo Opening $SHELL login shell for $USER on $OCI_HOST_PREFIX-$id.region...
    ssh $OCI_HOST_PREFIX-$id.$region pfzsh -c 'echo "PATH=\"$PATH\"" > .zshenv'
    ssh -t $OCI_HOST_PREFIX-$id.$region sudo iscsiadm modify discovery -s enable
    ssh $OCI_HOST_PREFIX-$id.$region
  done

  echo Step 3. Create $OCI_ZPOOL_MAP[tank], service accounts, permissions, and rm /etc/mail.
  for id in {1..$ad}
  do
    sleep 2
    ssh -t $OCI_HOST_PREFIX-$id.$region sudo pkg install network/rsync
    ssh -t $OCI_HOST_PREFIX-$id.$region sudo zpool create $OCI_ZPOOL_MAP[tank] c2t0d0s2
    ssh -t $OCI_HOST_PREFIX-$id.$region sudo zfs allow -ld joe create,mount,snapshot,clone,destroy,hold,keysource,checksum,encryption $OCI_ZPOOL_MAP[tank]
    ssh -t $OCI_HOST_PREFIX-$id.$region zfs create -o mountpoint=/x1 $OCI_ZPOOL_MAP[tank]/x1
    ssh -t $OCI_HOST_PREFIX-$id.$region sudo -s "mkdir /x1/tmp && chmod a+rwxt /x1/tmp"
    ssh -t $OCI_HOST_PREFIX-$id.$region sudo rm -rf /etc/mail
  done
  echo Pre-sync prep complete.
}

oci_ship_wc () {
  local vol=x1/wc
  zfs destroy -Rr tank/$vol@baseline
  zfs snapshot -r tank/$vol@baseline
  local TMPFILE="/x1/tmp/oci-$(basename $vol)-baseline.zfs.lzo"
  [[ -f $TMPFILE ]] || zfs send -rc tank/$vol@baseline | lzop -c > $TMPFILE
  for region ad in ${(kv)OCI_AD}
  do
    for id in {1..$ad}
    do
      for tries in {1..10}; rsync --stats --progress --partial --inplace $TMPFILE $OCI_HOST_PREFIX-$id.$region:$TMPFILE && break
      ssh -t $OCI_HOST_PREFIX-$id.$region sudo -s "zfs destroy -rR $OCI_ZPOOL_MAP[tank]/$vol; zfs create -p $OCI_ZPOOL_MAP[tank]/$vol; /usr/local/bin/lzop -d <$TMPFILE | zfs receive -F $OCI_ZPOOL_MAP[tank]/$vol && rm $TMPFILE"
      ssh -t $OCI_HOST_PREFIX-$id.$region sudo zfs allow -ld httpd create,mount,snapshot,clone,destroy $OCI_ZPOOL_MAP[tank]/$vol
    done
  done
}

_oci_post_sync () {
  echo Adjusting and Reloading config files.
  sed -i -e "s/OCI_AD=[(]/OCI_AD=( [$region]=$ad/" ~/.zshenv
  . ~/.zshenv

  echo Restablishing Firewall config.
  oci_region_scp $region ~/pf_ssh_only.conf
  oci_region_exec $region sudo mv -f pf_ssh_only.conf /etc/firewall/pf.conf
  oci_region_exec $region sudo svcadm enable firewall


  echo Fixing up /etc/hosts and /x1/logs.
  oci_region_exec $region sudo -s 'echo 127.0.0.1 localhost.localdomain localhost $(hostname) >> /etc/hosts'
  oci_region_exec $region sudo mkdir -p /x1/logs/httpd /x1/logs/svnpubsub /x1/tmp /x1/repos/svn-auth
  oci_region_exec $region sudo chown svn:other /x1/repos/svn-auth
  oci_region_exec $region sudo chmod a+rwxt /x1/tmp
  oci_region_ship_zones $region $slice

  echo Post-sync prep complete: refreshing ssh connections to $region.
  rm -f ~/.ssh/sockets/*.$region*
  ssh-refresh.sh
}

oci_ship_zone () {
  local zone=$1
  local LAST=$(realpath --relative-to ~ ~/.zulu-last | sed -e 's/^\.zulu-//')
  local vol=VARSHARE/zones/$zone
  zoneadm -z $zone shutdown
  zoneadm -z $zone detach
  zfs snapshot -r rpool/$vol@$LAST
  zoneadm -z $zone attach
  zoneadm -z $zone boot

  local TMPFILE="/x1/tmp/oci-$(basename $vol)-$LAST.zfs.lzo"
  [[ -f $TMPFILE ]] || zfs send -rc rpool/$vol@$LAST | lzop -c > $TMPFILE

  for region ad in ${(kv)OCI_AD}
  do
    for id in {1..$ad}
    do
      ssh -t $OCI_HOST_PREFIX-$id.$region sudo zoneadm -z $zone halt
      ssh -t $OCI_HOST_PREFIX-$id.$region sudo zoneadm -z $zone detach
      ssh -t $OCI_HOST_PREFIX-$id.$region sudo zoneadm -z $zone uninstall
      ssh -t $OCI_HOST_PREFIX-$id.$region sudo zonecfg -z $zone delete -F
      ssh -t $OCI_HOST_PREFIX-$id.$region sudo zfs destroy -Rrf rpool1/$vol
      zonecfg -z $zone export > $zone.cfg
      scp $zone.cfg$OCI_HOST_PREFIX-$id.$region:.
      ssh -t $OCI_HOST_PREFIX-$id.$region sudo zonecfg -z $zone -f $zone.cfg
      for tries in {1..10}; rsync --stats --progress --partial --inplace $TMPFILE $OCI_HOST_PREFIX-$id.$region:$TMPFILE && break
      ssh -t $OCI_HOST_PREFIX-$id.$region pfzsh -c "'/usr/local/bin/lzop -d <$TMPFILE | zfs receive -F $OCI_ZONE_MAP[rpool]/$vol && rm $TMPFILE'"
      ssh -t $OCI_HOST_PREFIX-$id.$region sudo zoneadm -z $zone attach
      ssh -t $OCI_HOST_PREFIX-$id.$region sudo zoneadm -z $zone boot
     done
  done
  rm $TMPFILE
}

oci_region_ship_zones () {
  local region=$1
  local slice=${2-}
  local ad=$OCI_AD[$region]
  local LAST=$(realpath --relative-to ~ ~/.zulu-last | sed -e 's/^\.zulu-//')
  local vol=rpool/VARSHARE/zones
  local target_vol=rpool1/VARSHARE/zones

  oci_region_exec $region sudo pkg install service/file-system/nfs
  oci_region_exec $region sudo dladm create-etherstub etherstub0
  oci_region_exec $region sudo dladm create-vnic -l etherstub0 gz0
  oci_region_exec $region sudo dladm create-vnic -l etherstub0 www0
  oci_region_exec $region sudo dladm create-vnic -l etherstub0 www1
  oci_region_exec $region sudo dladm create-vnic -l etherstub0 cms0
  oci_region_exec $region sudo dladm create-vnic -l etherstub0 cms1
  oci_region_exec $region sudo ipadm create-ip gz0
  oci_region_exec $region sudo ipadm create-addr -T static -a 192.168.254.1/24 gz0
  oci_region_exec $region sudo ipadm set-ifprop -p forwarding=on -m ipv4 net0
  oci_region_exec $region sudo ipadm set-ifprop -p forwarding=on -m ipv4 gz0

  for zone in ${OCI_ZONES[@]}
  do
    zoneadm -z $zone shutdown
    zoneadm -z $zone detach
  done

  zfs snapshot -r $vol@$LAST >/dev/null 2>&1

  for zone in ${OCI_ZONES[@]}
  do
    zoneadm -z $zone attach
    zoneadm -z $zone boot
  done

  for id in {1..$ad}
  do
    [[ -z "$slice" || $slice -eq $id ]] || continue
    ssh -t $OCI_HOST_PREFIX-$id.$region sudo svcadm disable smtp:sendmail
    ssh -t $OCI_HOST_PREFIX-$id.$region sudo svcadm disable site/svnwcsub
    ssh -t $OCI_HOST_PREFIX-$id.$region sudo -s "mkdir -p /x1/repos/svn-auth && chown svn:other /x1/repos/svn-auth"
    ssh -t $OCI_HOST_PREFIX-$id.$region sudo svcadm enable site/svnwcsub
    for zone in ${OCI_ZONES[@]}
    do
      ssh -t $OCI_HOST_PREFIX-$id.$region sudo zoneadm -z $zone halt
      ssh -t $OCI_HOST_PREFIX-$id.$region sudo zoneadm -z $zone detach
      ssh -t $OCI_HOST_PREFIX-$id.$region sudo zoneadm -z $zone uninstall
      ssh -t $OCI_HOST_PREFIX-$id.$region sudo zonecfg -z $zone delete -F
      zonecfg -z $zone export > $zone.cfg; scp $zone.cfg $OCI_HOST_PREFIX-$id.$region:.
      ssh -t $OCI_HOST_PREFIX-$id.$region sudo zonecfg -z $zone -f $zone.cfg
      echo Shipping $vol/$zone@$LAST to $OCI_HOST_PREFIX-$id.$region ...
      local TMPFILE="/x1/tmp/oci-zone-$zone-$LAST.zfs.lzo"
      [[ -f $TMPFILE ]] || (zfs send -rc $vol/$zone@$LAST | lzop -c > $TMPFILE)
      for tries in {1..10}; rsync --stats --progress --partial --inplace $TMPFILE $OCI_HOST_PREFIX-$id.$region:$TMPFILE && break
      ssh -t $OCI_HOST_PREFIX-$id.$region $SHELL -c "'sudo zfs destroy -rR $target_vol/$zone; /usr/local/bin/lzop -d <$TMPFILE | sudo zfs receive -F $target_vol/$zone && rm $TMPFILE'"
    done

    for zone in ${OCI_ZONES[@]}
    do
      ssh -t $OCI_HOST_PREFIX-$id.$region zoneadm -z $zone attach
      ssh -t $OCI_HOST_PREFIX-$id.$region zoneadm -z $zone boot
    done
  done

  zfs destroy -r $vol@$LAST
  rm -f /x1/tmp/oci-zone-*
  echo All zones synced to $region.
}

oci_region_setup () {
  local region=$1
  local ad=${2-1}
  local slice=${3-}
  local LAST=$(realpath --relative-to ~ ~/.zulu-last | sed -e 's/^\.zulu-//')

  OCI_AD[$region]=$ad

  [[ -z "$slice" ]] && _oci_pre_sync

  sed -i -e "s/ \\[$region\\]=$ad//g" ~/.zshenv
  rm -rf /x1/httpd/cores/*
  for id in {1..$ad}
  do
    [[ -z "$slice" || $slice -eq $id ]] || continue
    for volume in ${ZFS_EXPORTS[@]}
    do
      local vol=${volume#*/}
      local dst_mount=$vol
      local dst_pool=$OCI_ZPOOL_MAP[${volume%%/*}]
      local TMPFILE="/x1/tmp/oci-$(basename $vol)-$LAST.zfs.gz"

      echo Syncing /$dst_mount ...
      zfs snapshot -r $volume@$LAST >/dev/null 2>&1
      [[ -f "$TMPFILE" ]] || (zfs send -rc $volume@$LAST | gzip -c > $TMPFILE)
      for tries in {1..10}
      do
        rsync -vv --progress --stats --partial --inplace $TMPFILE $OCI_HOST_PREFIX-$id.$region:$TMPFILE && ssh $OCI_HOST_PREFIX-$id.$region pfzsh -c "'(sudo zfs destroy -Rr $dst_pool/$vol; sudo zfs create -p $dst_pool/$vol) >/dev/null 2>&1; gzip -d <$TMPFILE | sudo zfs receive -F -o mountpoint=/$dst_mount $dst_pool/$vol && rm $TMPFILE'" && break
      done
      echo Done with /$vol on $OCI_HOST_PREFIX-$id.$region after $tries tries: zfs receive exit status=$?.
    done
  done

  [[ -z "$slice" ]] && _oci_post_sync

  echo "All set: $region initialized to $LAST."
}

oci_release () {
  local slice=${1-}
  local ZULU=$(date -Iseconds | tr '+' 'Z')
  local LAST=$(realpath --relative-to ~ ~/.zulu-last | sed -e 's/^\.zulu-//')
  [[ -n "$LAST" ]] || return 1

  for region ad in ${(kv)OCI_AD}
  do
    for id in {1..$ad}
    do
      [[ -z "$slice" || $slice -eq $id ]] || continue
      echo Releasing $ZULU to $OCI_HOST_PREFIX-$id.$region...

      for svc in ${OCI_SITE_SVCS[@]}
      do
        ssh -t $OCI_HOST_PREFIX-$id.$region sudo svcadm disable site/$svc
      done

      for volume in ${ZFS_EXPORTS[@]}
      do
        local vol=${volume#*/}

        local dst_pool=$OCI_ZPOOL_MAP[${volume%%/*}]

        local TMPFILE=/x1/tmp/oci-$(basename $vol)-$ZULU.zfs.lzo
        zfs snapshot -r $volume@$ZULU >/dev/null 2>&1

        [[ -f $TMPFILE ]] || zfs send -RcI $LAST $volume@$ZULU | lzop -c > $TMPFILE
        for tries in {1..10}; rsync --stats --progress --partial --inplace $TMPFILE $OCI_HOST_PREFIX-$id.$region:$TMPFILE && break
        ssh -t $OCI_HOST_PREFIX-$id.$region pfzsh -c "'/usr/local/bin/lzop -d <$TMPFILE | sudo zfs receive -F $dst_pool/$vol && rm $TMPFILE'" || return $?
      done

      for zone in $OCI_ZONES[@]
      do
        ssh -t $OCI_HOST_PREFIX-$id.$region zoneadm -z $zone reboot
      done

      for svc in ${OCI_SITE_SVCS[@]}
      do
        ssh -t $OCI_HOST_PREFIX-$id.$region sudo svcadm enable site/$svc
      done

      echo $OCI_HOST_PREFIX-$id.$region $ZULU release complete.
    done
  done

  touch ~/.zulu-$ZULU
  if [[ -z "$slice" ]]
  then
    ln -s -f $(realpath --relative-to ~ ~/.zulu-last) ~/.zulu-rollback
    ln -s -f .zulu-$ZULU ~/.zulu-last
  fi
  rm /x1/tmp/oci-*
  echo "Released $ZULU to OCI $slice"
}

oci_ship_image_src () {
  for region in $@
  do
    local filepath=/rpool/dc/diskimage/media/solaris_diskimage.vmdk
    [[ -f $filepath ]] || sudo distro_const build ~/dc_diskimage_x86.xml
    sudo chown joe:adm $filepath
    oci os object put --bucket-name boot-images --file $filepath --storage-tier InfrequentAccess --name oci-solaris-zeus --region $region
  done
}

oci_ship_crons () {
  local slice=${1-}
  for region ad in ${(kv)OCI_AD}
  do
    for id in {1..$ad}
    do
      [[ -z "$slice" || $slice -eq $id ]] || continue
      for file in root httpd
      do
        local cron_path=/var/spool/cron/crontabs/$file
        sudo cat $cron_path > /tmp/$file
        scp /tmp/$file $OCI_HOST_PREFIX-$id.$region:/tmp/$file
        ssh -t $OCI_HOST_PREFIX-$id.$region sudo cp /tmp/$file $cron_path
        ssh $OCI_HOST_PREFIX-$id.$region rm /tmp/$file
        rm /tmp/$file
      done
      ssh -t $OCI_HOST_PREFIX-$id.$region sudo svcadm restart cron
    done
  done
}

oci_region_exec () {
  local region=$1
  shift
  local ad=$OCI_AD[$region]
  for i in {1..$ad}
  do
    ssh -t $OCI_HOST_PREFIX-$i.$region "$@"
  done
}

oci_region_scp () {
  local region=$1
  shift
  local ad=$OCI_AD[$region]
  for i in {1..$ad}
  do
    scp "$@" $OCI_HOST_PREFIX-$i.$region:.
  done
}

oci_region_site_svcs () {
  local region=$1
  local action=${2-restart}
  local ad=$OCI_AD[$region]
  for i in {1..$ad}
  do
    for svc in ${OCI_SITE_SVCS[@]}
    do
      echo -n Performing $action on site/$svc ...
      ssh -t $OCI_HOST_PREFIX-$i.$region sudo svcadm $action site/$svc
      sleep 2
      echo done.
    done
  done
}

oci_rollback () {
  local TARGET=$(realpath --relative-to ~ ~/.zulu-rollback | sed -e 's/^\.zulu-//')
  [[ -n "$TARGET" ]] || return 1
  for region ad in ${(kv)OCI_AD}
  do
    for id in {1..$ad}
    do
      for svc in ${OCI_SITE_SVCS[@]}
      do
        ssh -t $OCI_HOST_PREFIX-$id.$region sudo svcadm disable site/$svc
      done

      for volume in ${ZFS_EXPORTS[@]}
      do
        local vol=${volume#*/}
        ssh -t $OCI_HOST_PREFIX-$id.$region zfs rollback -R $OCI_ZPOOL_MAP[${volume%%/*}]/$vol@$TARGET
      done

      for zone in $OCI_ZONES[@]
      do
        ssh -t $OCI_HOST_PREFIX-$id.$region sudo zoneadm -z $zone reboot
      done

      for svc in ${OCI_SITE_SVCS[@]}
      do
        ssh -t $OCI_HOST_PREFIX-$id.$region sudo svcadm enable site/$svc
      done

      echo $OCI_HOST_PREFIX-$id.$region rollback complete.
    done
  done

  echo Rolled back from $(realpath --relative-to ~ ~/.zulu-last | sed -e 's/^\.zulu-//') to $TARGET.
  rm $(realpath ~/.zulu-last)
  ln -s -f .zulu-$TARGET ~/.zulu-last
  TARGET=$(echo ~/.zulu-2* | tr ' ' '\n' | tail -n 2 | head -n 1 | sed -e 's/^.*\.zulu-//')
  ln -s -f .zulu-$TARGET ~/.zulu-rollback
}

oci_tail_logs () {
  local kind=${1-access}
  local pcre=${2-}
  for region ad in ${(kv)OCI_AD}
  do
    for id in {1..$ad}
    do
      ssh $OCI_HOST_PREFIX-$id.$region $SHELL -c "'PATH=\"$PATH\"; tail -F /x1/logs/httpd/${kind}_log | grep --line-buffered -Pve \"^[\\d.]+ |Go|libwww|python\" | grep --line-buffered --color=always -Pie \"$pcre\"'" &
    done
  done
  wait
}

oci_region_upgrade () {
  local region=$1
  local slice=${2-}
  local ad=$OCI_AD[$region]
  for i in {1..$ad}
  do
    [[ -z "$slice" || $slice -eq $id ]] || continue
    ssh -t $OCI_HOST_PREFIX-$i.$region sudo pkg set-publisher -G "'*'" -g "$PKG_REPOS" solaris
    ssh -t $OCI_HOST_PREFIX-$i.$region sudo pkg refresh
    ssh -t $OCI_HOST_PREFIX-$i.$region sudo -s "pkg update && reboot"
    echo $OCI_HOST_PREFIX-$i.$region upgraded.
  done
}

oci_region_zlogin () {
  local region=$1
  local zone=$2
  shift; shift;
  oci_region_exec $region zlogin -l $USER $zone "$@"
}
